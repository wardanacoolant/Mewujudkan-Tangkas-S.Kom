{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   no  genre  playlist  danceability  energy  key  loudness  mode  \\\n0   1  Blues         0         0.598   0.735    2   -10.882     1   \n1   2  Blues         0         0.692   0.493    9    -9.662     0   \n2   3  Blues         0         0.821   0.376    0   -13.622     1   \n3   4  Blues         0         0.661   0.342    9   -16.361     0   \n4   5  Blues         0         0.542   0.588    2    -9.268     1   \n\n   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n0       0.0973        0.4400          0.000215     0.681    0.615  111.129   \n1       0.0325        0.0934          0.001660     0.128    0.280   86.644   \n2       0.0487        0.6690          0.000014     0.106    0.824  119.039   \n3       0.0430        0.8440          0.000128     0.260    0.588  146.118   \n4       0.0665        0.6700          0.158000     0.241    0.881  113.948   \n\n   duration_ms  \n0       321133  \n1       301133  \n2       170000  \n3       188400  \n4       238533  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>genre</th>\n      <th>playlist</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Blues</td>\n      <td>0</td>\n      <td>0.598</td>\n      <td>0.735</td>\n      <td>2</td>\n      <td>-10.882</td>\n      <td>1</td>\n      <td>0.0973</td>\n      <td>0.4400</td>\n      <td>0.000215</td>\n      <td>0.681</td>\n      <td>0.615</td>\n      <td>111.129</td>\n      <td>321133</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Blues</td>\n      <td>0</td>\n      <td>0.692</td>\n      <td>0.493</td>\n      <td>9</td>\n      <td>-9.662</td>\n      <td>0</td>\n      <td>0.0325</td>\n      <td>0.0934</td>\n      <td>0.001660</td>\n      <td>0.128</td>\n      <td>0.280</td>\n      <td>86.644</td>\n      <td>301133</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Blues</td>\n      <td>0</td>\n      <td>0.821</td>\n      <td>0.376</td>\n      <td>0</td>\n      <td>-13.622</td>\n      <td>1</td>\n      <td>0.0487</td>\n      <td>0.6690</td>\n      <td>0.000014</td>\n      <td>0.106</td>\n      <td>0.824</td>\n      <td>119.039</td>\n      <td>170000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Blues</td>\n      <td>0</td>\n      <td>0.661</td>\n      <td>0.342</td>\n      <td>9</td>\n      <td>-16.361</td>\n      <td>0</td>\n      <td>0.0430</td>\n      <td>0.8440</td>\n      <td>0.000128</td>\n      <td>0.260</td>\n      <td>0.588</td>\n      <td>146.118</td>\n      <td>188400</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Blues</td>\n      <td>0</td>\n      <td>0.542</td>\n      <td>0.588</td>\n      <td>2</td>\n      <td>-9.268</td>\n      <td>1</td>\n      <td>0.0665</td>\n      <td>0.6700</td>\n      <td>0.158000</td>\n      <td>0.241</td>\n      <td>0.881</td>\n      <td>113.948</td>\n      <td>238533</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "df = pd.read_csv(\"Data Fix.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability = df.danceability\n",
    "energy = df.energy\n",
    "key = df.key\n",
    "loudness = df.loudness\n",
    "mode = df.mode\n",
    "speechiness = df.speechiness\n",
    "acousticness = df.acousticness\n",
    "instrumentalness = df.instrumentalness\n",
    "liveness = df.liveness\n",
    "valence = df.valence\n",
    "tempo = df.tempo\n",
    "duration_ms = df.duration_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "745 0.76156218 0.58992806 0.71634121 0.60842754\n 0.80061665 0.48304214 0.38437821 0.64953751 0.70709147 0.37410072\n 0.75436793 0.668037   0.45118191 0.50359712 0.70400822 0.31243577\n 0.663926   0.63926002 0.61973279 0.54470709 0.55806783 0.69167523\n 0.28879753 0.3987667  0.04624872 0.45015416 0.00822199 0.16649538\n 0.08016444 0.09146968 0.47893114 0.30215827 0.23329908 0.22404933\n 0.71634121 0.04110997 0.11921891 0.53545735 0.24049332 0.41726619\n 0.08941418 0.03494347 0.32271326 0.54162384 0.1294964  0.35971223\n 0.00822199 0.32682425 0.02055498 0.24974306 0.84378212 0.28160329\n 0.01027749 0.1397739  0.0061665  0.09866393 0.25077081 0.0020555\n 0.45323741 0.0626927  0.01027749 0.29393628 0.34121274 0.00719424\n 0.40698869 0.39568345 0.55190134 0.81706064 0.68756423 0.0647482\n 0.39157246 0.44090442 0.23329908 0.2651593 ]\n\nTempo\n[0.48630821 0.59948968 0.44974438 0.32457219 0.47327743 0.47203861\n 0.03586121 0.64486396 0.32071242 0.32701748 0.60465299 0.22371888\n 0.26964786 0.55088428 0.21762645 0.19906256 0.5332264  0.5041325\n 0.56415543 0.45278597 0.4920216  0.52224338 0.54807381 0.16760657\n 0.46524818 0.45876746 0.75082511 0.62732164 0.41914355 0.05688426\n 0.08466538 0.26447068 0.61988407 0.59683637 0.52613089 0.59679939\n 0.42366896 0.03944826 0.43206801 0.48901698 0.27935507 0.50383204\n 0.47095232 0.46678747 0.61855279 0.62486248 0.44042083 0.46087069\n 0.62104893 0.61924154 0.65093328 0.41903723 0.56208455 0.52258082\n 0.28076955 0.60504128 0.68938308 0.54645132 0.61021846 0.64457274\n 0.65523681 0.1848623  0.62288868 0.42107112 0.61645881 0.54786118\n 0.62362828 0.31847976 0.54043747 0.54767628 0.65023066 1.\n 0.46432831 0.43442547 0.7838019  0.62242643 0.62045263 0.47663798\n 0.62655893 0.58427709 0.62805199 0.61593185 0.55004761 0.59341111\n 0.60315531 0.37198961 0.46952398 0.5839905  0.21134912 0.24590217\n 0.63544334 0.60136641 0.61367145 0.53790897 0.60563758 0.66463432\n 0.68933686 0.69435225 0.11252045 0.64771603 0.28782346 0.31443971\n 0.16779147 0.42145479 0.21441845 0.27917942 0.62534322 0.63863285\n 0.64850648 0.66005344 0.56180721 0.56997513 0.38981852 0.33526861\n 0.41722984 0.56638809 0.41070752 0.52873335 0.56051753 0.5608596\n 0.56123864 0.57951131 0.38991097 0.23705474 0.21440458 0.48683055\n 0.21465881 0.47293537 0.43569203 0.53305537 0.23213642 0.62088252\n 0.34419    0.6440504  0.43747631 0.18010114 0.62100733 0.35279244\n 0.35271848 0.57287805 0.31641813 0.55143436 0.30671092 0.62106742\n 0.0757671  0.46138379 0.51924801 0.58383333 0.4223007  0.26042601\n 0.53768247 0.42685847 0.40831307 0.47818189 0.53800142 0.43600636\n 0.41746096 0.41235774 0.51877652 0.4220742  0.44866734 0.52370409\n 0.40779535 0.39912358 0.41277377 0.45006333 0.41763662 0.40822524\n 0.51948376 0.37604353 0.43131454 0.44521434 0.43610806 0.41754417\n 0.41757653 0.43144859 0.42687234 0.43136077 0.41258887 0.43596938\n 0.60555437 0.46136992 0.40769366 0.42188006 0.40850722 0.37138406\n 0.41273216 0.40847486 0.43583533 0.42677064 0.42676602 0.51472723\n 0.41714663 0.49205858 0.43613579 0.41741012 0.43761036 0.30557841\n 0.41763199 0.33423318 0.51517099 0.59299509 0.58328788 0.51918792\n 0.42689083 0.26837205 0.58399974 0.05356994 0.42721902 0.49158708\n 0.54698291 0.46837298 0.57056219 0.12933704 0.47140533 0.48205553\n 0.49222499 0.50077195 0.58377324 0.30593434 0.42809729 0.53341592\n 0.49618183 0.43639927 0.5042157  0.50090601 0.54218015 0.50422495\n 0.30638735 0.49096305 0.38896798 0.42588313 0.52794753 0.49389832\n 0.57486109 0.57019239 0.49120342 0.64866826 0.46124049 0.45436686\n 0.06476097 0.53381808 0.46842383 0.49157784 0.38551499 0.44536226\n 0.51592907 0.21461721 0.4421219  0.44532991 0.20528442 0.40612664\n 0.56736343 0.54868398 0.63350652 0.41760426 0.5216101  0.22794845\n 0.62391487 0.47796001 0.41477992 0.57389962 0.40837779 0.46316344\n 0.51475496 0.52382889 0.57904444 0.44860725 0.58387493 0.19656642\n 0.17691163 0.35259367 0.57479638 0.6257084  0.2324415  0.20522895\n 0.27972025 0.52789668 0.51292446 0.70669428 0.53780266 0.59759446\n 0.33409912 0.63737554 0.25913171 0.62601348 0.16961273 0.56099365\n 0.55897825 0.46436066 0.58670852 0.11167916 0.58327863 0.46578901\n 0.54224024 0.31460612 0.33080329 0.3527231  0.26428578 0.27916555\n 0.54380264 0.59464994 0.54651604 0.21182061 0.56614772 0.5111448\n 0.56550057 0.56881027 0.58312147 0.61125389 0.59611527 0.5965544\n 0.57455139 0.56811689 0.57042351 0.35323158 0.61931088 0.52458698\n 0.19603021 0.16340011 0.55963926 0.37115756 0.55247904 0.18664195\n 0.30718241 0.63032163 0.46371814 0.33400667 0.32968003 0.44494162\n 0.56165929 0.35276008 0.38070761 0.43167972 0.5599351  0.54177337\n 0.40865976 0.44535302 0.56227408 0.52709699 0.65326763 0.53525105\n 0.53291669 0.5470846  0.32920854 0.26022724 0.22810561 0.64689785\n 0.55605222 0.48229589 0.55589967 0.50264406 0.49153624 0.43261808\n 0.45806484 0.71383139 0.36336406 0.42694167 0.44524208 0.42492627\n 0.71576359 0.59365611 0.50449767 0.61040798 0.46474433 0.28758771\n 0.14457737 0.73734133 0.62096573 0.4638337  0.44037923 0.35794651\n 0.65338782 0.5295053  0.50248227 0.52381503 0.63014136 0.51845295\n 0.41967975 0.38033781 0.53776105 0.08131408 0.58467925 0.57783797\n 0.5468581  0.4637921  0.47735446 0.48678895 0.57014616 0.50063328\n 0.50471493 0.47311565 0.57961763 0.62107667 0.57468082 0.48217109\n 0.53777492 0.07435724 0.50069337 0.33436261 0.37529006 0.51383971\n 0.45342849 0.35330091 0.33541653 0.46926512 0.43024675 0.58418926\n 0.34886795 0.53117402 0.52314477 0.37724075 0.3187155  0.57460686\n 0.32304215 0.36406205 0.19625209 0.51918792 0.56600442 0.34650124\n 0.52768404 0.50647147 0.36190335 0.44665194 0.27252304 0.58959294\n 0.51874879 0.29824715 0.47874121 0.45647933 0.45439459 0.39879538\n 0.51555003 0.43572439 0.53171947 0.53392902 0.38973994 0.32222397\n 0.56083648 0.35423466 0.42169053 0.17766509 0.52988897 0.3750312\n 0.35244113 0.35257518 0.43600174 0.43266893 0.3998077  0.16786543\n 0.17366202 0.45465345 0.5669659  0.22264184 0.41254264 0.47762257\n 0.44511727 0.60696885 0.31593739 0.52356079 0.32584799 0.36229164\n 0.45932216 0.63044182 0.57451903 0.43117587 0.46852552 0.18558803\n 0.52381965 0.37133322 0.45446393 0.54688121 0.5240554  0.56569009\n 0.52472103 0.33017926 0.47386911 0.37120841 0.15795945 0.34344578\n 0.16772213 0.28327956 0.51581813 0.54913698 0.         0.33913763\n 0.50929581 0.47772888 0.43522978 0.47759945 0.44527444 0.27891594\n 0.1679209  0.4083593  0.26916712 0.50533434 0.2515416  0.42678451\n 0.43581222 0.35226086 0.35229321 0.6077177  0.39886934 0.26927344\n 0.54278569 0.44567197 0.20953248 0.58398125 0.38032394 0.4681511\n 0.58404597 0.29808537 0.47919421 0.47295848 0.64840478 0.68174212\n 0.48689064 0.58342655 0.60056209 0.56308763 0.57052983 0.54720016\n 0.55313081 0.56480257 0.65360045 0.39544408 0.22541533 0.40852571\n 0.47344846 0.22701471 0.39822682 0.61546498 0.6717252  0.50989211\n 0.444937   0.34503592 0.36341953 0.41742398 0.26025035 0.34069078\n 0.40234545 0.57499052 0.55145747 0.55632494 0.63351114 0.62873612\n 0.40241478 0.46366729 0.49110172 0.37094493 0.38593101 0.64134625\n 0.23864487 0.34360295 0.54516627 0.30574482 0.4498322  0.56730334\n 0.2789298  0.4221158  0.68180221 0.41165513 0.20525669 0.57019239\n 0.37552118 0.55214622 0.62575462 0.62082243 0.35283404 0.19488384\n 0.40859042 0.37998188 0.33446892 0.49167029 0.22427358 0.45995082\n 0.42642396 0.65332772 0.63539712 0.63599804 0.64403654 0.2681548\n 0.57269315 0.59406288 0.35293112 0.41709579 0.5603881  0.45802786\n 0.61619533 0.34360295 0.195494   0.40835005 0.52244215 0.41539471\n 0.39836549 0.63408896 0.57955754 0.4643884  0.6909501  0.43493857\n 0.58406446 0.65783927 0.39900802 0.42666895 0.44533915 0.4266597\n 0.43595089 0.3988     0.4447521  0.49144379 0.64783622 0.17711502\n 0.56564387 0.35294036 0.53783039 0.2786201  0.4223007  0.46357947\n 0.52363013 0.26031969 0.41773369 0.41745172 0.19143547 0.25011325\n 0.51397839 0.54895671 0.52624645 0.33382178 0.20525206 0.08491499\n 0.33541653 0.27874028 0.5839304  0.25971415 0.26004696 0.50535283\n 0.57265617 0.5514436  0.31999593 0.37159208 0.44514038 0.44523283\n 0.53182579 0.37092182 0.41281537 0.32055063 0.3616861  0.25009938\n 0.40869211 0.34370464 0.35908364 0.5210138  0.46864571 0.06068394\n 0.4385441  0.53486276 0.52857618 0.45983988 0.56372091 0.40238243\n 0.48708016 0.45169969 0.44127137 0.19665887 0.23313025 0.6264295\n 0.09119695 0.55720321 0.55202603 0.57471317 0.49096767 0.66162046\n 0.62927233 0.30330415 0.3977507  0.37303891 0.31370936 0.33745042\n 0.43265968 0.14251574 0.43834534 0.38536707 0.55170246 0.40862278\n 0.60090416 0.47033753 0.39065981 0.43302024 0.16767129 0.41379996\n 0.51462553 0.49725887 0.54321096 0.68323981 0.41752106 0.41472445\n 0.58754056 0.04150064 0.47094308 0.54549909]\n[0.48630821 0.59948968 0.44974438 0.32457219 0.47327743 0.47203861\n 0.03586121 0.64486396 0.32071242 0.32701748 0.60465299 0.22371888\n 0.26964786 0.55088428 0.21762645 0.19906256 0.5332264  0.5041325\n 0.56415543 0.45278597 0.4920216  0.52224338 0.54807381 0.16760657\n 0.46524818 0.45876746 0.75082511 0.62732164 0.41914355 0.05688426\n 0.08466538 0.26447068 0.61988407 0.59683637 0.52613089 0.59679939\n 0.42366896 0.03944826 0.43206801 0.48901698 0.27935507 0.50383204\n 0.47095232 0.46678747 0.61855279 0.62486248 0.44042083 0.46087069\n 0.62104893 0.61924154 0.65093328 0.41903723 0.56208455 0.52258082\n 0.28076955 0.60504128 0.68938308 0.54645132 0.61021846 0.64457274\n 0.65523681 0.1848623  0.62288868 0.42107112 0.61645881 0.54786118\n 0.62362828 0.31847976 0.54043747 0.54767628 0.65023066 1.\n 0.46432831 0.43442547 0.7838019  0.62242643 0.62045263 0.47663798\n 0.62655893 0.58427709 0.62805199 0.61593185 0.55004761 0.59341111\n 0.60315531 0.37198961 0.46952398 0.5839905  0.21134912 0.24590217\n 0.63544334 0.60136641 0.61367145 0.53790897 0.60563758 0.66463432\n 0.68933686 0.69435225 0.11252045 0.64771603 0.28782346 0.31443971\n 0.16779147 0.42145479 0.21441845 0.27917942 0.62534322 0.63863285\n 0.64850648 0.66005344 0.56180721 0.56997513 0.38981852 0.33526861\n 0.41722984 0.56638809 0.41070752 0.52873335 0.56051753 0.5608596\n 0.56123864 0.57951131 0.38991097 0.23705474 0.21440458 0.48683055\n 0.21465881 0.47293537 0.43569203 0.53305537 0.23213642 0.62088252\n 0.34419    0.6440504  0.43747631 0.18010114 0.62100733 0.35279244\n 0.35271848 0.57287805 0.31641813 0.55143436 0.30671092 0.62106742\n 0.0757671  0.46138379 0.51924801 0.58383333 0.4223007  0.26042601\n 0.53768247 0.42685847 0.40831307 0.47818189 0.53800142 0.43600636\n 0.41746096 0.41235774 0.51877652 0.4220742  0.44866734 0.52370409\n 0.40779535 0.39912358 0.41277377 0.45006333 0.41763662 0.40822524\n 0.51948376 0.37604353 0.43131454 0.44521434 0.43610806 0.41754417\n 0.41757653 0.43144859 0.42687234 0.43136077 0.41258887 0.43596938\n 0.60555437 0.46136992 0.40769366 0.42188006 0.40850722 0.37138406\n 0.41273216 0.40847486 0.43583533 0.42677064 0.42676602 0.51472723\n 0.41714663 0.49205858 0.43613579 0.41741012 0.43761036 0.30557841\n 0.41763199 0.33423318 0.51517099 0.59299509 0.58328788 0.51918792\n 0.42689083 0.26837205 0.58399974 0.05356994 0.42721902 0.49158708\n 0.54698291 0.46837298 0.57056219 0.12933704 0.47140533 0.48205553\n 0.49222499 0.50077195 0.58377324 0.30593434 0.42809729 0.53341592\n 0.49618183 0.43639927 0.5042157  0.50090601 0.54218015 0.50422495\n 0.30638735 0.49096305 0.38896798 0.42588313 0.52794753 0.49389832\n 0.57486109 0.57019239 0.49120342 0.64866826 0.46124049 0.45436686\n 0.06476097 0.53381808 0.46842383 0.49157784 0.38551499 0.44536226\n 0.51592907 0.21461721 0.4421219  0.44532991 0.20528442 0.40612664\n 0.56736343 0.54868398 0.63350652 0.41760426 0.5216101  0.22794845\n 0.62391487 0.47796001 0.41477992 0.57389962 0.40837779 0.46316344\n 0.51475496 0.52382889 0.57904444 0.44860725 0.58387493 0.19656642\n 0.17691163 0.35259367 0.57479638 0.6257084  0.2324415  0.20522895\n 0.27972025 0.52789668 0.51292446 0.70669428 0.53780266 0.59759446\n 0.33409912 0.63737554 0.25913171 0.62601348 0.16961273 0.56099365\n 0.55897825 0.46436066 0.58670852 0.11167916 0.58327863 0.46578901\n 0.54224024 0.31460612 0.33080329 0.3527231  0.26428578 0.27916555\n 0.54380264 0.59464994 0.54651604 0.21182061 0.56614772 0.5111448\n 0.56550057 0.56881027 0.58312147 0.61125389 0.59611527 0.5965544\n 0.57455139 0.56811689 0.57042351 0.35323158 0.61931088 0.52458698\n 0.19603021 0.16340011 0.55963926 0.37115756 0.55247904 0.18664195\n 0.30718241 0.63032163 0.46371814 0.33400667 0.32968003 0.44494162\n 0.56165929 0.35276008 0.38070761 0.43167972 0.5599351  0.54177337\n 0.40865976 0.44535302 0.56227408 0.52709699 0.65326763 0.53525105\n 0.53291669 0.5470846  0.32920854 0.26022724 0.22810561 0.64689785\n 0.55605222 0.48229589 0.55589967 0.50264406 0.49153624 0.43261808\n 0.45806484 0.71383139 0.36336406 0.42694167 0.44524208 0.42492627\n 0.71576359 0.59365611 0.50449767 0.61040798 0.46474433 0.28758771\n 0.14457737 0.73734133 0.62096573 0.4638337  0.44037923 0.35794651\n 0.65338782 0.5295053  0.50248227 0.52381503 0.63014136 0.51845295\n 0.41967975 0.38033781 0.53776105 0.08131408 0.58467925 0.57783797\n 0.5468581  0.4637921  0.47735446 0.48678895 0.57014616 0.50063328\n 0.50471493 0.47311565 0.57961763 0.62107667 0.57468082 0.48217109\n 0.53777492 0.07435724 0.50069337 0.33436261 0.37529006 0.51383971\n 0.45342849 0.35330091 0.33541653 0.46926512 0.43024675 0.58418926\n 0.34886795 0.53117402 0.52314477 0.37724075 0.3187155  0.57460686\n 0.32304215 0.36406205 0.19625209 0.51918792 0.56600442 0.34650124\n 0.52768404 0.50647147 0.36190335 0.44665194 0.27252304 0.58959294\n 0.51874879 0.29824715 0.47874121 0.45647933 0.45439459 0.39879538\n 0.51555003 0.43572439 0.53171947 0.53392902 0.38973994 0.32222397\n 0.56083648 0.35423466 0.42169053 0.17766509 0.52988897 0.3750312\n 0.35244113 0.35257518 0.43600174 0.43266893 0.3998077  0.16786543\n 0.17366202 0.45465345 0.5669659  0.22264184 0.41254264 0.47762257\n 0.44511727 0.60696885 0.31593739 0.52356079 0.32584799 0.36229164\n 0.45932216 0.63044182 0.57451903 0.43117587 0.46852552 0.18558803\n 0.52381965 0.37133322 0.45446393 0.54688121 0.5240554  0.56569009\n 0.52472103 0.33017926 0.47386911 0.37120841 0.15795945 0.34344578\n 0.16772213 0.28327956 0.51581813 0.54913698 0.         0.33913763\n 0.50929581 0.47772888 0.43522978 0.47759945 0.44527444 0.27891594\n 0.1679209  0.4083593  0.26916712 0.50533434 0.2515416  0.42678451\n 0.43581222 0.35226086 0.35229321 0.6077177  0.39886934 0.26927344\n 0.54278569 0.44567197 0.20953248 0.58398125 0.38032394 0.4681511\n 0.58404597 0.29808537 0.47919421 0.47295848 0.64840478 0.68174212\n 0.48689064 0.58342655 0.60056209 0.56308763 0.57052983 0.54720016\n 0.55313081 0.56480257 0.65360045 0.39544408 0.22541533 0.40852571\n 0.47344846 0.22701471 0.39822682 0.61546498 0.6717252  0.50989211\n 0.444937   0.34503592 0.36341953 0.41742398 0.26025035 0.34069078\n 0.40234545 0.57499052 0.55145747 0.55632494 0.63351114 0.62873612\n 0.40241478 0.46366729 0.49110172 0.37094493 0.38593101 0.64134625\n 0.23864487 0.34360295 0.54516627 0.30574482 0.4498322  0.56730334\n 0.2789298  0.4221158  0.68180221 0.41165513 0.20525669 0.57019239\n 0.37552118 0.55214622 0.62575462 0.62082243 0.35283404 0.19488384\n 0.40859042 0.37998188 0.33446892 0.49167029 0.22427358 0.45995082\n 0.42642396 0.65332772 0.63539712 0.63599804 0.64403654 0.2681548\n 0.57269315 0.59406288 0.35293112 0.41709579 0.5603881  0.45802786\n 0.61619533 0.34360295 0.195494   0.40835005 0.52244215 0.41539471\n 0.39836549 0.63408896 0.57955754 0.4643884  0.6909501  0.43493857\n 0.58406446 0.65783927 0.39900802 0.42666895 0.44533915 0.4266597\n 0.43595089 0.3988     0.4447521  0.49144379 0.64783622 0.17711502\n 0.56564387 0.35294036 0.53783039 0.2786201  0.4223007  0.46357947\n 0.52363013 0.26031969 0.41773369 0.41745172 0.19143547 0.25011325\n 0.51397839 0.54895671 0.52624645 0.33382178 0.20525206 0.08491499\n 0.33541653 0.27874028 0.5839304  0.25971415 0.26004696 0.50535283\n 0.57265617 0.5514436  0.31999593 0.37159208 0.44514038 0.44523283\n 0.53182579 0.37092182 0.41281537 0.32055063 0.3616861  0.25009938\n 0.40869211 0.34370464 0.35908364 0.5210138  0.46864571 0.06068394\n 0.4385441  0.53486276 0.52857618 0.45983988 0.56372091 0.40238243\n 0.48708016 0.45169969 0.44127137 0.19665887 0.23313025 0.6264295\n 0.09119695 0.55720321 0.55202603 0.57471317 0.49096767 0.66162046\n 0.62927233 0.30330415 0.3977507  0.37303891 0.31370936 0.33745042\n 0.43265968 0.14251574 0.43834534 0.38536707 0.55170246 0.40862278\n 0.60090416 0.47033753 0.39065981 0.43302024 0.16767129 0.41379996\n 0.51462553 0.49725887 0.54321096 0.68323981 0.41752106 0.41472445\n 0.58754056 0.04150064 0.47094308 0.54549909]\n\nDuration\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n 0. 0. 0. 0.]\n\n"
    }
   ],
   "source": [
    "\n",
    "# Normalisasi Manual\n",
    "def normalize_list(list_normal):\n",
    "    max_value = max(list_normal)\n",
    "    min_value = min(list_normal)\n",
    "    newmax_value = 0\n",
    "    newmin_value = 1\n",
    "    for i in range(len(list_normal)):\n",
    "        list_normal[i] = (list_normal[i] - min_value) / (max_value - min_value) * (newmax_value - newmin_value) + newmin_value\n",
    "    return list_normal\n",
    "\n",
    "# Library\n",
    "def normalize_list_numpy(list_numpy):\n",
    "    normalized_list = minmax_scale(list_numpy)\n",
    "    return normalized_list\n",
    "\n",
    "# Fitur danceability\n",
    "danceability_array = np.array(danceability)\n",
    "danceability_array_numpy = np.array(danceability_array)\n",
    "print('Danceability')\n",
    "print(normalize_list(danceability_array))\n",
    "print(normalize_list_numpy(danceability_array))\n",
    "print('')\n",
    "\n",
    "# Fitur energy\n",
    "energy_array = np.array(energy)\n",
    "energy_array_numpy = np.array(energy_array)\n",
    "print('Energy')\n",
    "print(normalize_list(energy_array))\n",
    "print(normalize_list_numpy(energy_array))\n",
    "print('.2f')\n",
    "\n",
    "# Fitur key\n",
    "key_array = np.array(key)\n",
    "key_array_numpy = np.array(key_array)\n",
    "print('Key')\n",
    "print(normalize_list(key_array))\n",
    "print(normalize_list_numpy(key_array))\n",
    "print('')\n",
    "\n",
    "# Fitur loudness\n",
    "loudness_array = np.array(loudness)\n",
    "loudness_array_numpy = np.array(loudness_array)\n",
    "print('Laudness')\n",
    "print(normalize_list(loudness_array))\n",
    "print(normalize_list_numpy(loudness_array))\n",
    "print('')\n",
    "\n",
    "# Fitur speechiness\n",
    "speechiness_array = np.array(speechiness)\n",
    "speechiness_array_numpy = np.array(speechiness_array)\n",
    "print('Speechiness')\n",
    "print(normalize_list(speechiness_array))\n",
    "print(normalize_list_numpy(speechiness_array))\n",
    "print('')\n",
    "\n",
    "# Fitur acousticness\n",
    "acousticness_array = np.array(acousticness)\n",
    "acousticness_array_numpy = np.array(acousticness_array)\n",
    "print('Acousticness')\n",
    "print(normalize_list(acousticness_array))\n",
    "print(normalize_list_numpy(acousticness_array))\n",
    "print('')\n",
    "\n",
    "# Fitur instrumentalness\n",
    "instrumentalness_array = np.array(instrumentalness)\n",
    "instrumentalness_array_numpy = np.array(instrumentalness_array)\n",
    "print('Instrumentalness')\n",
    "print(normalize_list(instrumentalness_array))\n",
    "print(normalize_list_numpy(instrumentalness_array))\n",
    "print('')\n",
    "\n",
    "# Fitur liveness\n",
    "liveness_array = np.array(liveness)\n",
    "liveness_array_numpy = np.array(liveness_array)\n",
    "print('Liveness')\n",
    "print(normalize_list(liveness_array))\n",
    "print(normalize_list_numpy(liveness_array))\n",
    "print('')\n",
    "\n",
    "# Fitur valence\n",
    "valence_array = np.array(valence)\n",
    "valence_array_numpy = np.array(valence_array)\n",
    "print('Valence')\n",
    "print(normalize_list(valence_array))\n",
    "print(normalize_list_numpy(valence_array))\n",
    "print('')\n",
    "\n",
    "# Fitur tempo\n",
    "tempo_array = np.array(tempo)\n",
    "tempo_array_numpy = np.array(tempo_array)\n",
    "print('Tempo')\n",
    "print(normalize_list(tempo_array))\n",
    "print(normalize_list_numpy(tempo_array))\n",
    "print('')\n",
    "\n",
    "# Fitur duration_ms\n",
    "duration_ms_array = np.array(duration_ms)\n",
    "duration_ms_array_numpy = np.array(duration_ms_array)\n",
    "print('Duration')\n",
    "print(normalize_list(duration_ms_array))\n",
    "print(normalize_list_numpy(duration_ms_array))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_danceability = pd.DataFrame(data=normalize_list(danceability_array), index=df.index, columns=['danceability'])\n",
    "df_new_energy = pd.DataFrame(data=normalize_list(energy_array), index=df.index, columns=['energy'])\n",
    "df_new_key = pd.DataFrame(data=normalize_list(key_array), index=df.index, columns=['key'])\n",
    "df_new_loudness = pd.DataFrame(data=normalize_list(loudness_array), index=df.index, columns=['loudness'])\n",
    "df_new_speechiness = pd.DataFrame(data=normalize_list(speechiness_array), index=df.index, columns=['speechiness'])\n",
    "df_new_acousticness = pd.DataFrame(data=normalize_list(acousticness_array), index=df.index, columns=['acousticness'])\n",
    "df_new_instrumentalness = pd.DataFrame(data=normalize_list(instrumentalness_array), index=df.index, columns=['instrumentalness'])\n",
    "df_new_liveness = pd.DataFrame(data=normalize_list(liveness_array), index=df.index, columns=['liveness'])\n",
    "df_new_valence = pd.DataFrame(data=normalize_list(valence_array), index=df.index, columns=['valence'])\n",
    "df_new_tempo = pd.DataFrame(data=normalize_list(tempo_array), index=df.index, columns=['tempo'])\n",
    "df_new_duration_ms = pd.DataFrame(data=normalize_list(duration_ms_array), index=df.index, columns=['duration_ms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      no  playlist  danceability    energy  key  loudness  speechiness  \\\n0      1         0      0.625523  0.736882    1  0.745268     0.159770   \n1      2         0      0.723849  0.492918    1  0.777698     0.053366   \n2      3         0      0.858787  0.374968    0  0.672435     0.079967   \n3      4         0      0.691423  0.340693    1  0.599628     0.070608   \n4      5         0      0.566946  0.588689    1  0.788171     0.109195   \n..   ...       ...           ...       ...  ...       ...          ...   \n695  696        13      0.722803  0.581632    1  0.825864     0.106732   \n696  697        13      0.584728  0.537275    1  0.850744     0.054187   \n697  698        13      0.268828  0.336660    1  0.691574     0.058621   \n698  699        13      0.645397  0.882051    0  0.833466     0.074713   \n699  700        13      0.808577  0.417309    1  0.831313     0.069458   \n\n     acousticness  instrumentalness  liveness   valence     tempo  duration_ms  \n0        0.441764          0.000223  0.691804  0.632066  0.513692            1  \n1        0.093771          0.001722  0.125582  0.287770  0.400510            1  \n2        0.671685          0.000014  0.103056  0.846865  0.550256            1  \n3        0.847389          0.000133  0.260738  0.604317  0.675428            1  \n4        0.672689          0.163900  0.241284  0.905447  0.526723            1  \n..            ...               ...       ...       ...       ...          ...  \n695      0.559235          0.000048  0.145037  0.935252  0.585276            1  \n696      0.258029          0.000000  0.121487  0.608428  0.412459            1  \n697      0.738955          0.000000  0.252547  0.559096  0.958499            1  \n698      0.127506          0.000059  0.341627  0.766701  0.529057            1  \n699      0.505018          0.000089  0.085957  0.734841  0.454501            1  \n\n[700 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no</th>\n      <th>playlist</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.625523</td>\n      <td>0.736882</td>\n      <td>1</td>\n      <td>0.745268</td>\n      <td>0.159770</td>\n      <td>0.441764</td>\n      <td>0.000223</td>\n      <td>0.691804</td>\n      <td>0.632066</td>\n      <td>0.513692</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0.723849</td>\n      <td>0.492918</td>\n      <td>1</td>\n      <td>0.777698</td>\n      <td>0.053366</td>\n      <td>0.093771</td>\n      <td>0.001722</td>\n      <td>0.125582</td>\n      <td>0.287770</td>\n      <td>0.400510</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0.858787</td>\n      <td>0.374968</td>\n      <td>0</td>\n      <td>0.672435</td>\n      <td>0.079967</td>\n      <td>0.671685</td>\n      <td>0.000014</td>\n      <td>0.103056</td>\n      <td>0.846865</td>\n      <td>0.550256</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0.691423</td>\n      <td>0.340693</td>\n      <td>1</td>\n      <td>0.599628</td>\n      <td>0.070608</td>\n      <td>0.847389</td>\n      <td>0.000133</td>\n      <td>0.260738</td>\n      <td>0.604317</td>\n      <td>0.675428</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0.566946</td>\n      <td>0.588689</td>\n      <td>1</td>\n      <td>0.788171</td>\n      <td>0.109195</td>\n      <td>0.672689</td>\n      <td>0.163900</td>\n      <td>0.241284</td>\n      <td>0.905447</td>\n      <td>0.526723</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>695</th>\n      <td>696</td>\n      <td>13</td>\n      <td>0.722803</td>\n      <td>0.581632</td>\n      <td>1</td>\n      <td>0.825864</td>\n      <td>0.106732</td>\n      <td>0.559235</td>\n      <td>0.000048</td>\n      <td>0.145037</td>\n      <td>0.935252</td>\n      <td>0.585276</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>696</th>\n      <td>697</td>\n      <td>13</td>\n      <td>0.584728</td>\n      <td>0.537275</td>\n      <td>1</td>\n      <td>0.850744</td>\n      <td>0.054187</td>\n      <td>0.258029</td>\n      <td>0.000000</td>\n      <td>0.121487</td>\n      <td>0.608428</td>\n      <td>0.412459</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>697</th>\n      <td>698</td>\n      <td>13</td>\n      <td>0.268828</td>\n      <td>0.336660</td>\n      <td>1</td>\n      <td>0.691574</td>\n      <td>0.058621</td>\n      <td>0.738955</td>\n      <td>0.000000</td>\n      <td>0.252547</td>\n      <td>0.559096</td>\n      <td>0.958499</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>698</th>\n      <td>699</td>\n      <td>13</td>\n      <td>0.645397</td>\n      <td>0.882051</td>\n      <td>0</td>\n      <td>0.833466</td>\n      <td>0.074713</td>\n      <td>0.127506</td>\n      <td>0.000059</td>\n      <td>0.341627</td>\n      <td>0.766701</td>\n      <td>0.529057</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>699</th>\n      <td>700</td>\n      <td>13</td>\n      <td>0.808577</td>\n      <td>0.417309</td>\n      <td>1</td>\n      <td>0.831313</td>\n      <td>0.069458</td>\n      <td>0.505018</td>\n      <td>0.000089</td>\n      <td>0.085957</td>\n      <td>0.734841</td>\n      <td>0.454501</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>700 rows Ã— 13 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df_new = pd.concat([df['no'], df['genre'], df['playlist'], df_new_danceability, df_new_energy, df_new_key, df_new_loudness, df_new_speechiness, df_new_acousticness, df_new_instrumentalness, df_new_liveness, df_new_valence, df_new_tempo, df_new_duration_ms], axis=1, sort=False)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('data baru.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}